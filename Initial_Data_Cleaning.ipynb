{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjhr27l4l1aQMoQAnZMx3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osherlock1/AI-Image-Detection-Model/blob/main/Initial_Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports**"
      ],
      "metadata": {
        "id": "VZUAiZmPvdkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.utils.data import ConcatDataset\n"
      ],
      "metadata": {
        "id": "26aBVy3hvgRS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load in AI Dataset**"
      ],
      "metadata": {
        "id": "591JA8zIvATr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "509JeUYZYxYj",
        "outputId": "7d8b6c84-609f-4c57-b582-4351396d82ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/URI_spr25/ELE392/AI_Detection_Model/Datasets/AI_Images\""
      ],
      "metadata": {
        "id": "cMwdCSvDyS9y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AIDogDataset(Dataset):\n",
        "    def __init__(self, image_dir, label=1, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.filenames = sorted([\n",
        "            f for f in os.listdir(image_dir)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ])\n",
        "        self.label = label  # Fixed label for all images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, fname)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.label"
      ],
      "metadata": {
        "id": "cH_W-APoyfYW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "dataset = AIDogDataset(image_dir=image_dir, label=1, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "images, labels = next(iter(dataloader))\n",
        "print(f\"Batch shape: {images.shape}. Labels: {labels[:5]}\")"
      ],
      "metadata": {
        "id": "vPOXEt0ez6ln",
        "outputId": "9f4b45d3-fb1d-42b8-95a7-5c1d5f5106c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 3, 224, 224]). Labels: tensor([1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Real Dog Dataset**"
      ],
      "metadata": {
        "id": "U5Cyewgq2gud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_dogs_path = \"/content/drive/MyDrive/URI_spr25/ELE392/AI_Detection_Model/Datasets/Images\"  # Update if different\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "real_dataset = ImageFolder(root=real_dogs_path, transform=transform)"
      ],
      "metadata": {
        "id": "Kr8-ZOQ22mds"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total real images: {len(real_dataset)}\")\n"
      ],
      "metadata": {
        "id": "k7cHsJXq3oJf",
        "outputId": "5fc2153c-fa90-4eee-8195-825c6c3f4023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total real images: 20580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to Stanford Dogs (update if needed)\n",
        "\n",
        "\n",
        "class FixedLabelDataset(Dataset):\n",
        "    def __init__(self, base_dataset, fixed_label):\n",
        "        self.base = base_dataset\n",
        "        self.label = fixed_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, _ = self.base[idx]\n",
        "        return x, self.label"
      ],
      "metadata": {
        "id": "bcqQU2Yv49up"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 1000 real images from Stanford Dogs\n",
        "real_subset = torch.utils.data.Subset(real_dataset, range(1200))\n",
        "real_fixed = FixedLabelDataset(real_subset, fixed_label=0)\n",
        "\n",
        "# AI dataset is already using label=1, so we keep that as is\n",
        "ai_fixed = dataset  # your AI dataset with label=1\n",
        "\n",
        "# Combine\n",
        "from torch.utils.data import ConcatDataset, DataLoader\n",
        "\n",
        "combined = ConcatDataset([real_fixed, ai_fixed])\n",
        "dataloader = DataLoader(combined, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test again\n",
        "images, labels = next(iter(dataloader))\n",
        "print(\"Batch shape:\", images.shape)\n",
        "print(\"Label sample:\", labels[:10])"
      ],
      "metadata": {
        "id": "dQkOvpTe5n6Q",
        "outputId": "8e1867aa-363c-4693-a4d5-f349e72f8009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 3, 224, 224])\n",
            "Label sample: tensor([0, 1, 1, 0, 0, 0, 1, 1, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combine Datasets**"
      ],
      "metadata": {
        "id": "g8721Fkg5CTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_dataset = ConcatDataset([real_dataset_1000, dataset])\n",
        "dataloader = DataLoader(balanced_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Preview labels\n",
        "images, labels = next(iter(dataloader))\n",
        "print(\"Batch shape:\", images.shape)\n",
        "print(\"Label sample:\", labels[:10])"
      ],
      "metadata": {
        "id": "cMAB4Dvz5Dwb",
        "outputId": "b370558a-e118-4d1a-faee-e2c941d155b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 3, 224, 224])\n",
            "Label sample: tensor([0, 1, 1, 0, 1, 2, 1, 5, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(balanced_dataset)"
      ],
      "metadata": {
        "id": "zmHWVj1x7Mti",
        "outputId": "7776def4-033e-4d54-d87c-25a00e490d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2260"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the Dataset**"
      ],
      "metadata": {
        "id": "JFtseBN7-lag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "# 📁 Set destination folder in Drive\n",
        "save_root = \"/content/drive/MyDrive/URI_spr25/ELE392/AI_Detection_Model/Datasets/Processed_Dataset\"\n",
        "real_dir = os.path.join(save_root, \"real\")\n",
        "ai_dir = os.path.join(save_root, \"ai\")\n",
        "os.makedirs(real_dir, exist_ok=True)\n",
        "os.makedirs(ai_dir, exist_ok=True)\n",
        "\n",
        "# 💾 Save images into appropriate folders\n",
        "for i, (img, label) in enumerate(combined):\n",
        "    label = int(label)\n",
        "    folder = real_dir if label == 0 else ai_dir\n",
        "    filename = f\"{'real' if label == 0 else 'ai'}_{i:04}.png\"\n",
        "    save_path = os.path.join(folder, filename)\n",
        "    save_image(img, save_path)\n",
        "\n",
        "print(f\"✅ Saved {len(combined)} images to {save_root}\")"
      ],
      "metadata": {
        "id": "OWFAQbjs-mru",
        "outputId": "018fdd9a-263b-4dbf-d78d-1a3207df1176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2460 images to /content/drive/MyDrive/URI_spr25/ELE392/AI_Detection_Model/Datasets/Processed_Dataset\n"
          ]
        }
      ]
    }
  ]
}